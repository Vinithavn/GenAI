{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vinitha\\anaconda3\\envs\\langchain_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"langchain_api_key\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the LLM model for the generation\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the embedding model for the vector similarity search\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "vector_store_1 = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(web_path=\"https://jalammar.github.io/illustrated-transformer/\",\n",
    "                        bs_kwargs={\"parse_only\": bs4_strainer}\n",
    "                        )\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 24876\n",
      "\n",
      "The Illustrated Transformer\n",
      "\n",
      "Discussions:\n",
      "Hacker News (65 points, 4 comments), Reddit r/MachineLearning (29 points, 3 comments)\n",
      "\n",
      "\n",
      "Translations: Arabic, Chinese (Simplified) 1, Chinese (Simplified) 2, French 1, French 2, Italian, Japanese, Korean, Persian, Russian, Spanish 1, Spanish 2, Vietnamese\n",
      "\n",
      "Watch: MIT’s Deep Learning State of the Art lecture referencing this post\n",
      "\n",
      "Featured in courses at Stanford, Harvard, MIT, Princeton, CMU and others\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Update: This post has now become a book! Check \n"
     ]
    }
   ],
   "source": [
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 37 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "split_chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(split_chunks)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_ids = vector_store_1.add_documents(documents=split_chunks)\n",
    "retriever = vector_store_1.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_context_on_attention\",\n",
    "    \"Search and return information about Transformers and the attention mechanism used in the Language processing tasks\",\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict,List\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph.message import add_messages,BaseMessage\n",
    "from typing import Annotated, Sequence\n",
    "\n",
    "class State(TypedDict):\n",
    "    # The add_messages function defines how an update should be processed\n",
    "    # Default is to replace. add_messages says \"append\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a grader\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Data model\n",
    "class grade(BaseModel):\n",
    "    \"\"\"Binary score for relevance check.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "\n",
    "\n",
    "def grader(state:State):\n",
    "    question = state[\"messages\"][0].content\n",
    "    context = state[\"messages\"][-1].content\n",
    "    print(\"CONTEXT:\",context)\n",
    "    grader_prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "    llm_with_tool = llm.with_structured_output(grade)\n",
    "    chain = grader_prompt | llm_with_tool\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": context})\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        print(\"---DECISION: DOCS RELEVANT---\")\n",
    "        return \"generate\"\n",
    "\n",
    "    else:\n",
    "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "        print(score)\n",
    "        return \"end\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt = PromptTemplate.from_template(\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state:State):\n",
    "    print(\"GENERATING\")\n",
    "    question = state[\"messages\"][0].content\n",
    "    retrieved_contents = state[\"messages\"][-1].content\n",
    "    rag_message = rag_prompt.invoke({\"question\":question,\"context\":retrieved_contents})\n",
    "    llm_response = llm.invoke(rag_message).content\n",
    "    return {\"messages\":[llm_response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm2 = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state):  \n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model = llm2.bind_tools(tools)\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph structure to see the control flow\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "## Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(\"agent\", agent)  # agent\n",
    "retrieve = ToolNode([retriever_tool])\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieval\n",
    "workflow.add_node(\n",
    "    \"generate\", generate\n",
    ")  # Generating a response after we know the documents are relevant\n",
    "# Call agent node to decide to retrieve or not\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    # Assess agent decision\n",
    "    tools_condition,\n",
    "    {\n",
    "        # Translate the condition outputs to nodes in our graph\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Edges taken after the `action` node is called.\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    # Assess agent decision\n",
    "    grader,\n",
    "    {\n",
    "        \"generate\":\"generate\",\n",
    "        \"end\":END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n",
      "CONTEXT: Self-Attention at a High Level\n",
      "Don’t be fooled by me throwing around the word “self-attention” like it’s a concept everyone should be familiar with. I had personally never came across the concept until reading the Attention is All You Need paper. Let us distill how it works.\n",
      "Say the following sentence is an input sentence we want to translate:\n",
      "”The animal didn't cross the street because it was too tired”\n",
      "What does “it” in this sentence refer to? Is it referring to the street or to the animal? It’s a simple question to a human, but not as simple to an algorithm.\n",
      "When the model is processing the word “it”, self-attention allows it to associate “it” with “animal”.\n",
      "As the model processes each word (each position in the input sequence), self attention allows it to look at other positions in the input sequence for clues that can help lead to a better encoding for this word.\n",
      "\n",
      "As we are encoding the word \"it\" in encoder #5 (the top encoder in the stack), part of the attention mechanism was focusing on \"The Animal\", and baked a part of its representation into the encoding of \"it\".\n",
      "\n",
      "If we do the same self-attention calculation we outlined above, just eight different times with different weight matrices, we end up with eight different Z matrices\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This leaves us with a bit of a challenge. The feed-forward layer is not expecting eight matrices – it’s expecting a single matrix (a vector for each word). So we need a way to condense these eight down into a single matrix.\n",
      "How do we do that? We concat the matrices then multiply them by an additional weights matrix WO.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "That’s pretty much all there is to multi-headed self-attention. It’s quite a handful of matrices, I realize. Let me try to put them all in one visual so we can look at them in one place\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Now that we have touched upon attention heads, let’s revisit our example from before to see where the different attention heads are focusing as we encode the word “it” in our example sentence:\n",
      "\n",
      "Now that we have touched upon attention heads, let’s revisit our example from before to see where the different attention heads are focusing as we encode the word “it” in our example sentence:\n",
      "\n",
      "\n",
      "\n",
      "  As we encode the word \"it\", one attention head is focusing most on \"the animal\", while another is focusing on \"tired\" -- in a sense, the model's representation of the word \"it\" bakes in some of the representation of both \"animal\" and \"tired\".\n",
      "\n",
      "\n",
      "If we add all the attention heads to the picture, however, things can be harder to interpret:\n",
      "---DECISION: DOCS RELEVANT---\n",
      "GENERATING\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='An attention mechanism allows a model to focus on different parts of an input sequence when processing a specific word.  This helps the model to better understand context and relationships between words.  In the example,  self-attention helps associate \"it\" with \"animal\" by considering other parts of the sentence.\\n', additional_kwargs={}, response_metadata={}, id='a9cb04d9-2ddb-43b5-b44c-80907d1462e4')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = graph.invoke({\"messages\":[(\"user\",\"What is attention mechanism?\")]}) \n",
    "print(result[\"messages\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n",
      "content='' additional_kwargs={'function_call': {'name': 'retrieve_context_on_attention', 'arguments': '{\"query\": \"fastest animal in the world\"}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-a8cbc5f4-7c0c-4d89-97d6-1239397406bf-0' tool_calls=[{'name': 'retrieve_context_on_attention', 'args': {'query': 'fastest animal in the world'}, 'id': '5040a75d-3054-4562-aaa7-30a4eaf5ab1d', 'type': 'tool_call'}] usage_metadata={'input_tokens': 67, 'output_tokens': 14, 'total_tokens': 81, 'input_token_details': {'cache_read': 0}}\n",
      "CONTEXT: Acknowledgements\n",
      "Thanks to Illia Polosukhin, Jakob Uszkoreit, Llion Jones , Lukasz Kaiser, Niki Parmar, and Noam Shazeer for providing feedback on earlier versions of this post.\n",
      "Please hit me up on Twitter for any corrections or feedback.\n",
      "\n",
      "\n",
      "    Written on June 27, 2018\n",
      "\n",
      "As we are encoding the word \"it\" in encoder #5 (the top encoder in the stack), part of the attention mechanism was focusing on \"The Animal\", and baked a part of its representation into the encoding of \"it\".\n",
      "\n",
      "Now that we have touched upon attention heads, let’s revisit our example from before to see where the different attention heads are focusing as we encode the word “it” in our example sentence:\n",
      "\n",
      "\n",
      "\n",
      "  As we encode the word \"it\", one attention head is focusing most on \"the animal\", while another is focusing on \"tired\" -- in a sense, the model's representation of the word \"it\" bakes in some of the representation of both \"animal\" and \"tired\".\n",
      "\n",
      "\n",
      "If we add all the attention heads to the picture, however, things can be harder to interpret:\n",
      "\n",
      "Self-Attention at a High Level\n",
      "Don’t be fooled by me throwing around the word “self-attention” like it’s a concept everyone should be familiar with. I had personally never came across the concept until reading the Attention is All You Need paper. Let us distill how it works.\n",
      "Say the following sentence is an input sentence we want to translate:\n",
      "”The animal didn't cross the street because it was too tired”\n",
      "What does “it” in this sentence refer to? Is it referring to the street or to the animal? It’s a simple question to a human, but not as simple to an algorithm.\n",
      "When the model is processing the word “it”, self-attention allows it to associate “it” with “animal”.\n",
      "As the model processes each word (each position in the input sequence), self attention allows it to look at other positions in the input sequence for clues that can help lead to a better encoding for this word.\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "no\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the fastest animal in the world?', additional_kwargs={}, response_metadata={}, id='f6bc218b-691d-42f2-8cac-a39aa2cf3dcf'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'retrieve_context_on_attention', 'arguments': '{\"query\": \"fastest animal in the world\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-a8cbc5f4-7c0c-4d89-97d6-1239397406bf-0', tool_calls=[{'name': 'retrieve_context_on_attention', 'args': {'query': 'fastest animal in the world'}, 'id': '5040a75d-3054-4562-aaa7-30a4eaf5ab1d', 'type': 'tool_call'}], usage_metadata={'input_tokens': 67, 'output_tokens': 14, 'total_tokens': 81, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content='Acknowledgements\\nThanks to Illia Polosukhin, Jakob Uszkoreit, Llion Jones , Lukasz Kaiser, Niki Parmar, and Noam Shazeer for providing feedback on earlier versions of this post.\\nPlease hit me up on Twitter for any corrections or feedback.\\n\\n\\n    Written on June 27, 2018\\n\\nAs we are encoding the word \"it\" in encoder #5 (the top encoder in the stack), part of the attention mechanism was focusing on \"The Animal\", and baked a part of its representation into the encoding of \"it\".\\n\\nNow that we have touched upon attention heads, let’s revisit our example from before to see where the different attention heads are focusing as we encode the word “it” in our example sentence:\\n\\n\\n\\n  As we encode the word \"it\", one attention head is focusing most on \"the animal\", while another is focusing on \"tired\" -- in a sense, the model\\'s representation of the word \"it\" bakes in some of the representation of both \"animal\" and \"tired\".\\n\\n\\nIf we add all the attention heads to the picture, however, things can be harder to interpret:\\n\\nSelf-Attention at a High Level\\nDon’t be fooled by me throwing around the word “self-attention” like it’s a concept everyone should be familiar with. I had personally never came across the concept until reading the Attention is All You Need paper. Let us distill how it works.\\nSay the following sentence is an input sentence we want to translate:\\n”The animal didn\\'t cross the street because it was too tired”\\nWhat does “it” in this sentence refer to? Is it referring to the street or to the animal? It’s a simple question to a human, but not as simple to an algorithm.\\nWhen the model is processing the word “it”, self-attention allows it to associate “it” with “animal”.\\nAs the model processes each word (each position in the input sequence), self attention allows it to look at other positions in the input sequence for clues that can help lead to a better encoding for this word.', name='retrieve_context_on_attention', id='d8ed4875-80b5-4dd4-ada0-0ee5d7d15d9e', tool_call_id='5040a75d-3054-4562-aaa7-30a4eaf5ab1d')]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = graph.invoke({\"messages\":[(\"user\",\"What is the fastest animal in the world?\")]}) \n",
    "print(result[\"messages\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
